[
  {
    "word": "Loss Function",
    "trans": [
      {
        "cn": "损失函数"
      }
    ]
  },
  {
    "word": "Accept-Reject Sampling Method",
    "trans": [
      {
        "cn": "接受-拒绝抽样法/接受-拒绝采样法"
      }
    ]
  },
  {
    "word": "Accumulated Error Backpropagation",
    "trans": [
      {
        "cn": "累积误差反向传播"
      }
    ]
  },
  {
    "word": "Accuracy",
    "trans": [
      {
        "cn": "准确率"
      }
    ]
  },
  {
    "word": "Acquisition Function",
    "trans": [
      {
        "cn": "采集函数"
      }
    ]
  },
  {
    "word": "Action",
    "trans": [
      {
        "cn": "动作"
      }
    ]
  },
  {
    "word": "Activation Function",
    "trans": [
      {
        "cn": "激活函数"
      }
    ]
  },
  {
    "word": "Active Learning",
    "trans": [
      {
        "cn": "主动学习"
      }
    ]
  },
  {
    "word": "Adaptive Bitrate Algorithm",
    "trans": [
      {
        "cn": "自适应比特率算法"
      }
    ]
  },
  {
    "word": "Adaptive Boosting",
    "trans": [
      {
        "cn": "AdaBoost"
      }
    ]
  },
  {
    "word": "Adaptive Gradient Algorithm",
    "trans": [
      {
        "cn": "AdaGrad"
      }
    ]
  },
  {
    "word": "Adaptive Moment Estimation Algorithm",
    "trans": [
      {
        "cn": "Adam算法"
      }
    ]
  },
  {
    "word": "Adaptive Resonance Theory",
    "trans": [
      {
        "cn": "自适应谐振理论"
      }
    ]
  },
  {
    "word": "Additive Model",
    "trans": [
      {
        "cn": "加性模型"
      }
    ]
  },
  {
    "word": "Affinity Matrix",
    "trans": [
      {
        "cn": "亲和矩阵"
      }
    ]
  },
  {
    "word": "Agent",
    "trans": [
      {
        "cn": "智能体"
      }
    ]
  },
  {
    "word": "Algorithm",
    "trans": [
      {
        "cn": "算法"
      }
    ]
  },
  {
    "word": "Alpha-Beta Pruning",
    "trans": [
      {
        "cn": "α-β修剪法"
      }
    ]
  },
  {
    "word": "Anomaly Detection",
    "trans": [
      {
        "cn": "异常检测"
      }
    ]
  },
  {
    "word": "Approximate Inference",
    "trans": [
      {
        "cn": "近似推断"
      }
    ]
  },
  {
    "word": "Area Under ROC Curve",
    "trans": [
      {
        "cn": "AUC（ROC曲线下方面积，度量分类模型好坏的标准）"
      }
    ]
  },
  {
    "word": "Artificial Intelligence",
    "trans": [
      {
        "cn": "人工智能"
      }
    ]
  },
  {
    "word": "Artificial Neural Network",
    "trans": [
      {
        "cn": "人工神经网络"
      }
    ]
  },
  {
    "word": "Artificial Neuron",
    "trans": [
      {
        "cn": "人工神经元"
      }
    ]
  },
  {
    "word": "Attention",
    "trans": [
      {
        "cn": "注意力"
      }
    ]
  },
  {
    "word": "Attention Mechanism",
    "trans": [
      {
        "cn": "注意力机制"
      }
    ]
  },
  {
    "word": "Attribute",
    "trans": [
      {
        "cn": "属性"
      }
    ]
  },
  {
    "word": "Attribute Space",
    "trans": [
      {
        "cn": "属性空间"
      }
    ]
  },
  {
    "word": "Autoencoder",
    "trans": [
      {
        "cn": "自编码器"
      }
    ]
  },
  {
    "word": "Automatic Differentiation",
    "trans": [
      {
        "cn": "自动微分"
      }
    ]
  },
  {
    "word": "Autoregressive Model",
    "trans": [
      {
        "cn": "自回归模型"
      }
    ]
  },
  {
    "word": "Back Propagation",
    "trans": [
      {
        "cn": "反向传播"
      }
    ]
  },
  {
    "word": "Back Propagation Algorithm",
    "trans": [
      {
        "cn": "反向传播算法"
      }
    ]
  },
  {
    "word": "Back Propagation Through Time",
    "trans": [
      {
        "cn": "随时间反向传播"
      }
    ]
  },
  {
    "word": "Backward Induction",
    "trans": [
      {
        "cn": "反向归纳"
      }
    ]
  },
  {
    "word": "Backward Search",
    "trans": [
      {
        "cn": "反向搜索"
      }
    ]
  },
  {
    "word": "Bag of Words",
    "trans": [
      {
        "cn": "词袋"
      }
    ]
  },
  {
    "word": "Bandit",
    "trans": [
      {
        "cn": "赌博机/老虎机"
      }
    ]
  },
  {
    "word": "Base Learner",
    "trans": [
      {
        "cn": "基学习器"
      }
    ]
  },
  {
    "word": "Base Learning Algorithm",
    "trans": [
      {
        "cn": "基学习算法"
      }
    ]
  },
  {
    "word": "Baseline",
    "trans": [
      {
        "cn": "基准"
      }
    ]
  },
  {
    "word": "Batch",
    "trans": [
      {
        "cn": "批量"
      }
    ]
  },
  {
    "word": "Batch Normalization",
    "trans": [
      {
        "cn": "批量规范化"
      }
    ]
  },
  {
    "word": "Bayes Decision Rule",
    "trans": [
      {
        "cn": "贝叶斯决策准则"
      }
    ]
  },
  {
    "word": "Bayes Model Averaging",
    "trans": [
      {
        "cn": "贝叶斯模型平均"
      }
    ]
  },
  {
    "word": "Bayes Optimal Classifier",
    "trans": [
      {
        "cn": "贝叶斯最优分类器"
      }
    ]
  },
  {
    "word": "Bayes' Theorem",
    "trans": [
      {
        "cn": "贝叶斯定理"
      }
    ]
  },
  {
    "word": "Bayesian Decision Theory",
    "trans": [
      {
        "cn": "贝叶斯决策理论"
      }
    ]
  },
  {
    "word": "Bayesian Inference",
    "trans": [
      {
        "cn": "贝叶斯推断"
      }
    ]
  },
  {
    "word": "Bayesian Learning",
    "trans": [
      {
        "cn": "贝叶斯学习"
      }
    ]
  },
  {
    "word": "Bayesian Network",
    "trans": [
      {
        "cn": "贝叶斯网/贝叶斯网络"
      }
    ]
  },
  {
    "word": "Bayesian Optimization",
    "trans": [
      {
        "cn": "贝叶斯优化"
      }
    ]
  },
  {
    "word": "Beam Search",
    "trans": [
      {
        "cn": "束搜索"
      }
    ]
  },
  {
    "word": "Benchmark",
    "trans": [
      {
        "cn": "基准"
      }
    ]
  },
  {
    "word": "Belief Network",
    "trans": [
      {
        "cn": "信念网/信念网络"
      }
    ]
  },
  {
    "word": "Belief Propagation",
    "trans": [
      {
        "cn": "信念传播"
      }
    ]
  },
  {
    "word": "Bellman Equation",
    "trans": [
      {
        "cn": "贝尔曼方程"
      }
    ]
  },
  {
    "word": "Bernoulli Distribution",
    "trans": [
      {
        "cn": "伯努利分布"
      }
    ]
  },
  {
    "word": "Beta Distribution",
    "trans": [
      {
        "cn": "贝塔分布"
      }
    ]
  },
  {
    "word": "Between-Class Scatter Matrix",
    "trans": [
      {
        "cn": "类间散度矩阵"
      }
    ]
  },
  {
    "word": "BFGS",
    "trans": [
      {
        "cn": "BFGS"
      }
    ]
  },
  {
    "word": "Bias",
    "trans": [
      {
        "cn": "偏差/偏置"
      }
    ]
  },
  {
    "word": "Bias In Affine Function",
    "trans": [
      {
        "cn": "偏置"
      }
    ]
  },
  {
    "word": "Bias In Statistics",
    "trans": [
      {
        "cn": "偏差"
      }
    ]
  },
  {
    "word": "Bias Shift",
    "trans": [
      {
        "cn": "偏置偏移"
      }
    ]
  },
  {
    "word": "Bias-Variance Decomposition",
    "trans": [
      {
        "cn": "偏差 - 方差分解"
      }
    ]
  },
  {
    "word": "Bias-Variance Dilemma",
    "trans": [
      {
        "cn": "偏差 - 方差困境"
      }
    ]
  },
  {
    "word": "Bidirectional Recurrent Neural Network",
    "trans": [
      {
        "cn": "双向循环神经网络"
      }
    ]
  },
  {
    "word": "Bigram",
    "trans": [
      {
        "cn": "二元语法"
      }
    ]
  },
  {
    "word": "Bilingual Evaluation Understudy",
    "trans": [
      {
        "cn": "BLEU"
      }
    ]
  },
  {
    "word": "Binary Classification",
    "trans": [
      {
        "cn": "二分类"
      }
    ]
  },
  {
    "word": "Binomial Distribution",
    "trans": [
      {
        "cn": "二项分布"
      }
    ]
  },
  {
    "word": "Binomial Test",
    "trans": [
      {
        "cn": "二项检验"
      }
    ]
  },
  {
    "word": "Boltzmann Distribution",
    "trans": [
      {
        "cn": "玻尔兹曼分布"
      }
    ]
  },
  {
    "word": "Boltzmann Machine",
    "trans": [
      {
        "cn": "玻尔兹曼机"
      }
    ]
  },
  {
    "word": "Boosting",
    "trans": [
      {
        "cn": "Boosting（一种模型训练加速方式）"
      }
    ]
  },
  {
    "word": "Bootstrap Aggregating",
    "trans": [
      {
        "cn": "Bagging"
      }
    ]
  },
  {
    "word": "Bootstrap Sampling",
    "trans": [
      {
        "cn": "自助采样法"
      }
    ]
  },
  {
    "word": "Bootstrapping",
    "trans": [
      {
        "cn": "自助法/自举法"
      }
    ]
  },
  {
    "word": "Break-Event Point",
    "trans": [
      {
        "cn": "平衡点"
      }
    ]
  },
  {
    "word": "Bucketing",
    "trans": [
      {
        "cn": "分桶"
      }
    ]
  },
  {
    "word": "Calculus of Variations",
    "trans": [
      {
        "cn": "变分法"
      }
    ]
  },
  {
    "word": "Cascade-Correlation",
    "trans": [
      {
        "cn": "级联相关"
      }
    ]
  },
  {
    "word": "Catastrophic Forgetting",
    "trans": [
      {
        "cn": "灾难性遗忘"
      }
    ]
  },
  {
    "word": "Categorical Distribution",
    "trans": [
      {
        "cn": "类别分布"
      }
    ]
  },
  {
    "word": "Cell",
    "trans": [
      {
        "cn": "单元"
      }
    ]
  },
  {
    "word": "Chain Rule",
    "trans": [
      {
        "cn": "链式法则"
      }
    ]
  },
  {
    "word": "Chebyshev Distance",
    "trans": [
      {
        "cn": "切比雪夫距离"
      }
    ]
  },
  {
    "word": "Class",
    "trans": [
      {
        "cn": "类别"
      }
    ]
  },
  {
    "word": "Class-Imbalance",
    "trans": [
      {
        "cn": "类别不平衡"
      }
    ]
  },
  {
    "word": "Classification",
    "trans": [
      {
        "cn": "分类"
      }
    ]
  },
  {
    "word": "Classification And Regression Tree",
    "trans": [
      {
        "cn": "分类与回归树"
      }
    ]
  },
  {
    "word": "Classifier",
    "trans": [
      {
        "cn": "分类器"
      }
    ]
  },
  {
    "word": "Clique",
    "trans": [
      {
        "cn": "团"
      }
    ]
  },
  {
    "word": "Cluster",
    "trans": [
      {
        "cn": "簇"
      }
    ]
  },
  {
    "word": "Cluster Assumption",
    "trans": [
      {
        "cn": "聚类假设"
      }
    ]
  },
  {
    "word": "Clustering",
    "trans": [
      {
        "cn": "聚类"
      }
    ]
  },
  {
    "word": "Clustering Ensemble",
    "trans": [
      {
        "cn": "聚类集成"
      }
    ]
  },
  {
    "word": "Co-Training",
    "trans": [
      {
        "cn": "协同训练"
      }
    ]
  },
  {
    "word": "Coding Matrix",
    "trans": [
      {
        "cn": "编码矩阵"
      }
    ]
  },
  {
    "word": "Collaborative Filtering",
    "trans": [
      {
        "cn": "协同过滤"
      }
    ]
  },
  {
    "word": "Competitive Learning",
    "trans": [
      {
        "cn": "竞争型学习"
      }
    ]
  },
  {
    "word": "Comprehensibility",
    "trans": [
      {
        "cn": "可解释性"
      }
    ]
  },
  {
    "word": "Computation Graph",
    "trans": [
      {
        "cn": "计算图"
      }
    ]
  },
  {
    "word": "Computational Learning Theory",
    "trans": [
      {
        "cn": "计算学习理论"
      }
    ]
  },
  {
    "word": "Conditional Entropy",
    "trans": [
      {
        "cn": "条件熵"
      }
    ]
  },
  {
    "word": "Conditional Probability",
    "trans": [
      {
        "cn": "条件概率"
      }
    ]
  },
  {
    "word": "Conditional Probability Distribution",
    "trans": [
      {
        "cn": "条件概率分布"
      }
    ]
  },
  {
    "word": "Conditional Random Field",
    "trans": [
      {
        "cn": "条件随机场"
      }
    ]
  },
  {
    "word": "Conditional Risk",
    "trans": [
      {
        "cn": "条件风险"
      }
    ]
  },
  {
    "word": "Confidence",
    "trans": [
      {
        "cn": "置信度"
      }
    ]
  },
  {
    "word": "Confusion Matrix",
    "trans": [
      {
        "cn": "混淆矩阵"
      }
    ]
  },
  {
    "word": "Conjugate Distribution",
    "trans": [
      {
        "cn": "共轭分布"
      }
    ]
  },
  {
    "word": "Connection Weight",
    "trans": [
      {
        "cn": "连接权"
      }
    ]
  },
  {
    "word": "Connectionism",
    "trans": [
      {
        "cn": "连接主义"
      }
    ]
  },
  {
    "word": "Consistency",
    "trans": [
      {
        "cn": "一致性"
      }
    ]
  },
  {
    "word": "Constrained Optimization",
    "trans": [
      {
        "cn": "约束优化"
      }
    ]
  },
  {
    "word": "Context Variable",
    "trans": [
      {
        "cn": "上下文变量"
      }
    ]
  },
  {
    "word": "Context Vector",
    "trans": [
      {
        "cn": "上下文向量"
      }
    ]
  },
  {
    "word": "Context Window",
    "trans": [
      {
        "cn": "上下文窗口"
      }
    ]
  },
  {
    "word": "Context Word",
    "trans": [
      {
        "cn": "上下文词"
      }
    ]
  },
  {
    "word": "Contextual Bandit",
    "trans": [
      {
        "cn": "上下文赌博机/上下文老虎机"
      }
    ]
  },
  {
    "word": "Contingency Table",
    "trans": [
      {
        "cn": "列联表"
      }
    ]
  },
  {
    "word": "Continuous Attribute",
    "trans": [
      {
        "cn": "连续属性"
      }
    ]
  },
  {
    "word": "Contrastive Divergence",
    "trans": [
      {
        "cn": "对比散度"
      }
    ]
  },
  {
    "word": "Convergence",
    "trans": [
      {
        "cn": "收敛"
      }
    ]
  },
  {
    "word": "Convex Optimization",
    "trans": [
      {
        "cn": "凸优化"
      }
    ]
  },
  {
    "word": "Convex Quadratic Programming",
    "trans": [
      {
        "cn": "凸二次规划"
      }
    ]
  },
  {
    "word": "Convolution",
    "trans": [
      {
        "cn": "卷积"
      }
    ]
  },
  {
    "word": "Convolutional Kernel",
    "trans": [
      {
        "cn": "卷积核"
      }
    ]
  },
  {
    "word": "Convolutional Neural Network",
    "trans": [
      {
        "cn": "卷积神经网络"
      }
    ]
  },
  {
    "word": "Coordinate Descent",
    "trans": [
      {
        "cn": "坐标下降"
      }
    ]
  },
  {
    "word": "Corpus",
    "trans": [
      {
        "cn": "语料库"
      }
    ]
  },
  {
    "word": "Correlation Coefficient",
    "trans": [
      {
        "cn": "相关系数"
      }
    ]
  },
  {
    "word": "Cosine Similarity",
    "trans": [
      {
        "cn": "余弦相似度"
      }
    ]
  },
  {
    "word": "Cost",
    "trans": [
      {
        "cn": "代价"
      }
    ]
  },
  {
    "word": "Cost Curve",
    "trans": [
      {
        "cn": "代价曲线"
      }
    ]
  },
  {
    "word": "Cost Function",
    "trans": [
      {
        "cn": "代价函数"
      }
    ]
  },
  {
    "word": "Cost Matrix",
    "trans": [
      {
        "cn": "代价矩阵"
      }
    ]
  },
  {
    "word": "Cost-Sensitive",
    "trans": [
      {
        "cn": "代价敏感"
      }
    ]
  },
  {
    "word": "Covariance",
    "trans": [
      {
        "cn": "协方差"
      }
    ]
  },
  {
    "word": "Covariance Matrix",
    "trans": [
      {
        "cn": "协方差矩阵"
      }
    ]
  },
  {
    "word": "Critical Point",
    "trans": [
      {
        "cn": "临界点"
      }
    ]
  },
  {
    "word": "Cross Entropy",
    "trans": [
      {
        "cn": "交叉熵"
      }
    ]
  },
  {
    "word": "Cross Validation",
    "trans": [
      {
        "cn": "交叉验证"
      }
    ]
  },
  {
    "word": "Curse of Dimensionality",
    "trans": [
      {
        "cn": "维数灾难"
      }
    ]
  },
  {
    "word": "Cutting Plane Algorithm",
    "trans": [
      {
        "cn": "割平面法"
      }
    ]
  },
  {
    "word": "Data Mining",
    "trans": [
      {
        "cn": "数据挖掘"
      }
    ]
  },
  {
    "word": "Data Set",
    "trans": [
      {
        "cn": "数据集"
      }
    ]
  },
  {
    "word": "Davidon-Fletcher-Powell",
    "trans": [
      {
        "cn": "DFP"
      }
    ]
  },
  {
    "word": "Decision Boundary",
    "trans": [
      {
        "cn": "决策边界"
      }
    ]
  },
  {
    "word": "Decision Function",
    "trans": [
      {
        "cn": "决策函数"
      }
    ]
  },
  {
    "word": "Decision Stump",
    "trans": [
      {
        "cn": "决策树桩"
      }
    ]
  },
  {
    "word": "Decision Tree",
    "trans": [
      {
        "cn": "决策树"
      }
    ]
  },
  {
    "word": "Decoder",
    "trans": [
      {
        "cn": "解码器"
      }
    ]
  },
  {
    "word": "Decoding",
    "trans": [
      {
        "cn": "解码"
      }
    ]
  },
  {
    "word": "Deconvolution",
    "trans": [
      {
        "cn": "反卷积"
      }
    ]
  },
  {
    "word": "Deconvolutional Network",
    "trans": [
      {
        "cn": "反卷积网络"
      }
    ]
  },
  {
    "word": "Deduction",
    "trans": [
      {
        "cn": "演绎"
      }
    ]
  },
  {
    "word": "Deep Belief Network",
    "trans": [
      {
        "cn": "深度信念网络"
      }
    ]
  },
  {
    "word": "Deep Boltzmann Machine",
    "trans": [
      {
        "cn": "深度玻尔兹曼机"
      }
    ]
  },
  {
    "word": "Deep Convolutional Generative Adversarial Network",
    "trans": [
      {
        "cn": "深度卷积生成对抗网络"
      }
    ]
  },
  {
    "word": "Deep Learning",
    "trans": [
      {
        "cn": "深度学习"
      }
    ]
  },
  {
    "word": "Deep Neural Network",
    "trans": [
      {
        "cn": "深度神经网络"
      }
    ]
  },
  {
    "word": "Deep Q-Network",
    "trans": [
      {
        "cn": "深度Q网络"
      }
    ]
  },
  {
    "word": "Delta-Bar-Delta",
    "trans": [
      {
        "cn": "Delta-Bar-Delta"
      }
    ]
  },
  {
    "word": "Denoising",
    "trans": [
      {
        "cn": "去噪"
      }
    ]
  },
  {
    "word": "Denoising Autoencoder",
    "trans": [
      {
        "cn": "去噪自编码器"
      }
    ]
  },
  {
    "word": "Denoising Score Matching",
    "trans": [
      {
        "cn": "去躁分数匹配"
      }
    ]
  },
  {
    "word": "Density Estimation",
    "trans": [
      {
        "cn": "密度估计"
      }
    ]
  },
  {
    "word": "Density-Based Clustering",
    "trans": [
      {
        "cn": "密度聚类"
      }
    ]
  },
  {
    "word": "Derivative",
    "trans": [
      {
        "cn": "导数"
      }
    ]
  },
  {
    "word": "Determinant",
    "trans": [
      {
        "cn": "行列式"
      }
    ]
  },
  {
    "word": "Diagonal Matrix",
    "trans": [
      {
        "cn": "对角矩阵"
      }
    ]
  },
  {
    "word": "Dictionary Learning",
    "trans": [
      {
        "cn": "字典学习"
      }
    ]
  },
  {
    "word": "Dimension Reduction",
    "trans": [
      {
        "cn": "降维"
      }
    ]
  },
  {
    "word": "Directed Edge",
    "trans": [
      {
        "cn": "有向边"
      }
    ]
  },
  {
    "word": "Directed Graphical Model",
    "trans": [
      {
        "cn": "有向图模型"
      }
    ]
  },
  {
    "word": "Directed Separation",
    "trans": [
      {
        "cn": "有向分离"
      }
    ]
  },
  {
    "word": "Dirichlet Distribution",
    "trans": [
      {
        "cn": "狄利克雷分布"
      }
    ]
  },
  {
    "word": "Discriminative Model",
    "trans": [
      {
        "cn": "判别式模型"
      }
    ]
  },
  {
    "word": "Discriminator",
    "trans": [
      {
        "cn": "判别器"
      }
    ]
  },
  {
    "word": "Discriminator Network",
    "trans": [
      {
        "cn": "判别网络"
      }
    ]
  },
  {
    "word": "Distance Measure",
    "trans": [
      {
        "cn": "距离度量"
      }
    ]
  },
  {
    "word": "Distance Metric Learning",
    "trans": [
      {
        "cn": "距离度量学习"
      }
    ]
  },
  {
    "word": "Distributed Representation",
    "trans": [
      {
        "cn": "分布式表示"
      }
    ]
  },
  {
    "word": "Diverge",
    "trans": [
      {
        "cn": "发散"
      }
    ]
  },
  {
    "word": "Divergence",
    "trans": [
      {
        "cn": "散度"
      }
    ]
  },
  {
    "word": "Diversity",
    "trans": [
      {
        "cn": "多样性"
      }
    ]
  },
  {
    "word": "Diversity Measure",
    "trans": [
      {
        "cn": "多样性度量/差异性度量"
      }
    ]
  },
  {
    "word": "Domain Adaptation",
    "trans": [
      {
        "cn": "领域自适应"
      }
    ]
  },
  {
    "word": "Dominant Eigenvalue",
    "trans": [
      {
        "cn": "主特征值"
      }
    ]
  },
  {
    "word": "Dominant Strategy",
    "trans": [
      {
        "cn": "占优策略"
      }
    ]
  },
  {
    "word": "Down Sampling",
    "trans": [
      {
        "cn": "下采样"
      }
    ]
  },
  {
    "word": "Dropout",
    "trans": [
      {
        "cn": "暂退法"
      }
    ]
  },
  {
    "word": "Dropout Boosting",
    "trans": [
      {
        "cn": "暂退Boosting"
      }
    ]
  },
  {
    "word": "Dropout Method",
    "trans": [
      {
        "cn": "暂退法"
      }
    ]
  },
  {
    "word": "Dual Problem",
    "trans": [
      {
        "cn": "对偶问题"
      }
    ]
  },
  {
    "word": "Dummy Node",
    "trans": [
      {
        "cn": "哑结点"
      }
    ]
  },
  {
    "word": "Dynamic Bayesian Network",
    "trans": [
      {
        "cn": "动态贝叶斯网络"
      }
    ]
  },
  {
    "word": "Dynamic Programming",
    "trans": [
      {
        "cn": "动态规划"
      }
    ]
  },
  {
    "word": "Early Stopping",
    "trans": [
      {
        "cn": "早停"
      }
    ]
  },
  {
    "word": "Eigendecomposition",
    "trans": [
      {
        "cn": "特征分解"
      }
    ]
  },
  {
    "word": "Eigenvalue",
    "trans": [
      {
        "cn": "特征值"
      }
    ]
  },
  {
    "word": "Element-Wise Product",
    "trans": [
      {
        "cn": "逐元素积"
      }
    ]
  },
  {
    "word": "Embedding",
    "trans": [
      {
        "cn": "嵌入"
      }
    ]
  },
  {
    "word": "Empirical Conditional Entropy",
    "trans": [
      {
        "cn": "经验条件熵"
      }
    ]
  },
  {
    "word": "Empirical Distribution",
    "trans": [
      {
        "cn": "经验分布"
      }
    ]
  },
  {
    "word": "Empirical Entropy",
    "trans": [
      {
        "cn": "经验熵"
      }
    ]
  },
  {
    "word": "Empirical Error",
    "trans": [
      {
        "cn": "经验误差"
      }
    ]
  },
  {
    "word": "Empirical Risk",
    "trans": [
      {
        "cn": "经验风险"
      }
    ]
  },
  {
    "word": "Empirical Risk Minimization",
    "trans": [
      {
        "cn": "经验风险最小化"
      }
    ]
  },
  {
    "word": "Encoder",
    "trans": [
      {
        "cn": "编码器"
      }
    ]
  },
  {
    "word": "Encoding",
    "trans": [
      {
        "cn": "编码"
      }
    ]
  },
  {
    "word": "End-To-End",
    "trans": [
      {
        "cn": "端到端"
      }
    ]
  },
  {
    "word": "Energy Function",
    "trans": [
      {
        "cn": "能量函数"
      }
    ]
  },
  {
    "word": "Energy-Based Model",
    "trans": [
      {
        "cn": "基于能量的模型"
      }
    ]
  },
  {
    "word": "Ensemble Learning",
    "trans": [
      {
        "cn": "集成学习"
      }
    ]
  },
  {
    "word": "Ensemble Pruning",
    "trans": [
      {
        "cn": "集成修剪"
      }
    ]
  },
  {
    "word": "Entropy",
    "trans": [
      {
        "cn": "熵"
      }
    ]
  },
  {
    "word": "Episode",
    "trans": [
      {
        "cn": "回合"
      }
    ]
  },
  {
    "word": "Epoch",
    "trans": [
      {
        "cn": "轮"
      }
    ]
  },
  {
    "word": "Error",
    "trans": [
      {
        "cn": "误差"
      }
    ]
  },
  {
    "word": "Error Backpropagation Algorithm",
    "trans": [
      {
        "cn": "误差反向传播算法"
      }
    ]
  },
  {
    "word": "Error Backpropagation",
    "trans": [
      {
        "cn": "误差反向传播"
      }
    ]
  },
  {
    "word": "Error Correcting Output Codes",
    "trans": [
      {
        "cn": "纠错输出编码"
      }
    ]
  },
  {
    "word": "Error Rate",
    "trans": [
      {
        "cn": "错误率"
      }
    ]
  },
  {
    "word": "Error-Ambiguity Decomposition",
    "trans": [
      {
        "cn": "误差－分歧分解"
      }
    ]
  },
  {
    "word": "Estimator",
    "trans": [
      {
        "cn": "估计/估计量"
      }
    ]
  },
  {
    "word": "Euclidean Distance",
    "trans": [
      {
        "cn": "欧氏距离"
      }
    ]
  },
  {
    "word": "Evidence",
    "trans": [
      {
        "cn": "证据"
      }
    ]
  },
  {
    "word": "Evidence Lower Bound",
    "trans": [
      {
        "cn": "证据下界"
      }
    ]
  },
  {
    "word": "Exact Inference",
    "trans": [
      {
        "cn": "精确推断"
      }
    ]
  },
  {
    "word": "Example",
    "trans": [
      {
        "cn": "样例"
      }
    ]
  },
  {
    "word": "Expectation",
    "trans": [
      {
        "cn": "期望"
      }
    ]
  },
  {
    "word": "Expectation Maximization",
    "trans": [
      {
        "cn": "期望最大化"
      }
    ]
  },
  {
    "word": "Expected Loss",
    "trans": [
      {
        "cn": "期望损失"
      }
    ]
  },
  {
    "word": "Expert System",
    "trans": [
      {
        "cn": "专家系统"
      }
    ]
  },
  {
    "word": "Exploding Gradient",
    "trans": [
      {
        "cn": "梯度爆炸"
      }
    ]
  },
  {
    "word": "Exponential Loss Function",
    "trans": [
      {
        "cn": "指数损失函数"
      }
    ]
  },
  {
    "word": "Factor",
    "trans": [
      {
        "cn": "因子"
      }
    ]
  },
  {
    "word": "Factorization",
    "trans": [
      {
        "cn": "因子分解"
      }
    ]
  },
  {
    "word": "Feature",
    "trans": [
      {
        "cn": "特征"
      }
    ]
  },
  {
    "word": "Feature Engineering",
    "trans": [
      {
        "cn": "特征工程"
      }
    ]
  },
  {
    "word": "Feature Map",
    "trans": [
      {
        "cn": "特征图"
      }
    ]
  },
  {
    "word": "Feature Selection",
    "trans": [
      {
        "cn": "特征选择"
      }
    ]
  },
  {
    "word": "Feature Vector",
    "trans": [
      {
        "cn": "特征向量"
      }
    ]
  },
  {
    "word": "Featured Learning",
    "trans": [
      {
        "cn": "特征学习"
      }
    ]
  },
  {
    "word": "Feedforward",
    "trans": [
      {
        "cn": "前馈"
      }
    ]
  },
  {
    "word": "Feedforward Neural Network",
    "trans": [
      {
        "cn": "前馈神经网络"
      }
    ]
  },
  {
    "word": "Few-Shot Learning",
    "trans": [
      {
        "cn": "少试学习"
      }
    ]
  },
  {
    "word": "Filter",
    "trans": [
      {
        "cn": "滤波器"
      }
    ]
  },
  {
    "word": "Fine-Tuning",
    "trans": [
      {
        "cn": "微调"
      }
    ]
  },
  {
    "word": "Fluctuation",
    "trans": [
      {
        "cn": "振荡"
      }
    ]
  },
  {
    "word": "Forget Gate",
    "trans": [
      {
        "cn": "遗忘门"
      }
    ]
  },
  {
    "word": "Forward Propagation",
    "trans": [
      {
        "cn": "前向传播/正向传播"
      }
    ]
  },
  {
    "word": "Forward Stagewise Algorithm",
    "trans": [
      {
        "cn": "前向分步算法"
      }
    ]
  },
  {
    "word": "Fractionally Strided Convolution",
    "trans": [
      {
        "cn": "微步卷积"
      }
    ]
  },
  {
    "word": "Frobenius Norm",
    "trans": [
      {
        "cn": "Frobenius 范数"
      }
    ]
  },
  {
    "word": "Full Padding",
    "trans": [
      {
        "cn": "全填充"
      }
    ]
  },
  {
    "word": "Functional",
    "trans": [
      {
        "cn": "泛函"
      }
    ]
  },
  {
    "word": "Functional Neuron",
    "trans": [
      {
        "cn": "功能神经元"
      }
    ]
  },
  {
    "word": "Gated Recurrent Unit",
    "trans": [
      {
        "cn": "门控循环单元"
      }
    ]
  },
  {
    "word": "Gated RNN",
    "trans": [
      {
        "cn": "门控RNN"
      }
    ]
  },
  {
    "word": "Gaussian Distribution",
    "trans": [
      {
        "cn": "高斯分布"
      }
    ]
  },
  {
    "word": "Gaussian Kernel",
    "trans": [
      {
        "cn": "高斯核"
      }
    ]
  },
  {
    "word": "Gaussian Kernel Function",
    "trans": [
      {
        "cn": "高斯核函数"
      }
    ]
  },
  {
    "word": "Gaussian Mixture Model",
    "trans": [
      {
        "cn": "高斯混合模型"
      }
    ]
  },
  {
    "word": "Gaussian Process",
    "trans": [
      {
        "cn": "高斯过程"
      }
    ]
  },
  {
    "word": "Generalization Ability",
    "trans": [
      {
        "cn": "泛化能力"
      }
    ]
  },
  {
    "word": "Generalization Error",
    "trans": [
      {
        "cn": "泛化误差"
      }
    ]
  },
  {
    "word": "Generalization Error Bound",
    "trans": [
      {
        "cn": "泛化误差上界"
      }
    ]
  },
  {
    "word": "Generalize",
    "trans": [
      {
        "cn": "泛化"
      }
    ]
  },
  {
    "word": "Generalized Lagrange Function",
    "trans": [
      {
        "cn": "广义拉格朗日函数"
      }
    ]
  },
  {
    "word": "Generalized Linear Model",
    "trans": [
      {
        "cn": "广义线性模型"
      }
    ]
  },
  {
    "word": "Generalized Rayleigh Quotient",
    "trans": [
      {
        "cn": "广义瑞利商"
      }
    ]
  },
  {
    "word": "Generative Adversarial Network",
    "trans": [
      {
        "cn": "生成对抗网络"
      }
    ]
  },
  {
    "word": "Generative Model",
    "trans": [
      {
        "cn": "生成式模型"
      }
    ]
  },
  {
    "word": "Generator",
    "trans": [
      {
        "cn": "生成器"
      }
    ]
  },
  {
    "word": "Generator Network",
    "trans": [
      {
        "cn": "生成器网络"
      }
    ]
  },
  {
    "word": "Genetic Algorithm",
    "trans": [
      {
        "cn": "遗传算法"
      }
    ]
  },
  {
    "word": "Gibbs Distribution",
    "trans": [
      {
        "cn": "吉布斯分布"
      }
    ]
  },
  {
    "word": "Gibbs Sampling",
    "trans": [
      {
        "cn": "吉布斯采样/吉布斯抽样"
      }
    ]
  },
  {
    "word": "Gini Index",
    "trans": [
      {
        "cn": "基尼指数"
      }
    ]
  },
  {
    "word": "Global Markov Property",
    "trans": [
      {
        "cn": "全局马尔可夫性"
      }
    ]
  },
  {
    "word": "Global Minimum",
    "trans": [
      {
        "cn": "全局最小"
      }
    ]
  },
  {
    "word": "Gradient",
    "trans": [
      {
        "cn": "梯度"
      }
    ]
  },
  {
    "word": "Gradient Clipping",
    "trans": [
      {
        "cn": "梯度截断"
      }
    ]
  },
  {
    "word": "Gradient Descent",
    "trans": [
      {
        "cn": "梯度下降"
      }
    ]
  },
  {
    "word": "Gradient Descent Method",
    "trans": [
      {
        "cn": "梯度下降法"
      }
    ]
  },
  {
    "word": "Gradient Exploding Problem",
    "trans": [
      {
        "cn": "梯度爆炸问题"
      }
    ]
  },
  {
    "word": "Gram Matrix",
    "trans": [
      {
        "cn": "Gram 矩阵"
      }
    ]
  },
  {
    "word": "Graph Convolutional Network",
    "trans": [
      {
        "cn": "图卷积神经网络/图卷积网络"
      }
    ]
  },
  {
    "word": "Graph Neural Network",
    "trans": [
      {
        "cn": "图神经网络"
      }
    ]
  },
  {
    "word": "Graphical Model",
    "trans": [
      {
        "cn": "图模型"
      }
    ]
  },
  {
    "word": "Grid Search",
    "trans": [
      {
        "cn": "网格搜索"
      }
    ]
  },
  {
    "word": "Ground Truth",
    "trans": [
      {
        "cn": "真实值"
      }
    ]
  },
  {
    "word": "Hadamard Product",
    "trans": [
      {
        "cn": "Hadamard积"
      }
    ]
  },
  {
    "word": "Hamming Distance",
    "trans": [
      {
        "cn": "汉明距离"
      }
    ]
  },
  {
    "word": "Hard Margin",
    "trans": [
      {
        "cn": "硬间隔"
      }
    ]
  },
  {
    "word": "Hebbian Rule",
    "trans": [
      {
        "cn": "赫布法则"
      }
    ]
  },
  {
    "word": "Hidden Layer",
    "trans": [
      {
        "cn": "隐藏层"
      }
    ]
  },
  {
    "word": "Hidden Markov Model",
    "trans": [
      {
        "cn": "隐马尔可夫模型"
      }
    ]
  },
  {
    "word": "Hidden Variable",
    "trans": [
      {
        "cn": "隐变量"
      }
    ]
  },
  {
    "word": "Hierarchical Clustering",
    "trans": [
      {
        "cn": "层次聚类"
      }
    ]
  },
  {
    "word": "Hilbert Space",
    "trans": [
      {
        "cn": "希尔伯特空间"
      }
    ]
  },
  {
    "word": "Hinge Loss Function",
    "trans": [
      {
        "cn": "合页损失函数/Hinge损失函数"
      }
    ]
  },
  {
    "word": "Hold-Out",
    "trans": [
      {
        "cn": "留出法"
      }
    ]
  },
  {
    "word": "Hyperparameter",
    "trans": [
      {
        "cn": "超参数"
      }
    ]
  },
  {
    "word": "Hyperparameter Optimization",
    "trans": [
      {
        "cn": "超参数优化"
      }
    ]
  },
  {
    "word": "Hypothesis",
    "trans": [
      {
        "cn": "假设"
      }
    ]
  },
  {
    "word": "Hypothesis Space",
    "trans": [
      {
        "cn": "假设空间"
      }
    ]
  },
  {
    "word": "Hypothesis Test",
    "trans": [
      {
        "cn": "假设检验"
      }
    ]
  },
  {
    "word": "Identity Matrix",
    "trans": [
      {
        "cn": "单位矩阵"
      }
    ]
  },
  {
    "word": "Imitation Learning",
    "trans": [
      {
        "cn": "模仿学习"
      }
    ]
  },
  {
    "word": "Importance Sampling",
    "trans": [
      {
        "cn": "重要性采样"
      }
    ]
  },
  {
    "word": "Improved Iterative Scaling",
    "trans": [
      {
        "cn": "改进的迭代尺度法"
      }
    ]
  },
  {
    "word": "Incremental Learning",
    "trans": [
      {
        "cn": "增量学习"
      }
    ]
  },
  {
    "word": "Independent and Identically Distributed",
    "trans": [
      {
        "cn": "独立同分布"
      }
    ]
  },
  {
    "word": "Indicator Function",
    "trans": [
      {
        "cn": "指示函数"
      }
    ]
  },
  {
    "word": "Individual Learner",
    "trans": [
      {
        "cn": "个体学习器"
      }
    ]
  },
  {
    "word": "Induction",
    "trans": [
      {
        "cn": "归纳"
      }
    ]
  },
  {
    "word": "Inductive Bias",
    "trans": [
      {
        "cn": "归纳偏好"
      }
    ]
  },
  {
    "word": "Inductive Learning",
    "trans": [
      {
        "cn": "归纳学习"
      }
    ]
  },
  {
    "word": "Inductive Logic Programming",
    "trans": [
      {
        "cn": "归纳逻辑程序设计"
      }
    ]
  },
  {
    "word": "Inference",
    "trans": [
      {
        "cn": "推断"
      }
    ]
  },
  {
    "word": "Information Entropy",
    "trans": [
      {
        "cn": "信息熵"
      }
    ]
  },
  {
    "word": "Information Gain",
    "trans": [
      {
        "cn": "信息增益"
      }
    ]
  },
  {
    "word": "Inner Product",
    "trans": [
      {
        "cn": "内积"
      }
    ]
  },
  {
    "word": "Instance",
    "trans": [
      {
        "cn": "示例"
      }
    ]
  },
  {
    "word": "Internal Covariate Shift",
    "trans": [
      {
        "cn": "内部协变量偏移"
      }
    ]
  },
  {
    "word": "Inverse Matrix",
    "trans": [
      {
        "cn": "逆矩阵"
      }
    ]
  },
  {
    "word": "Inverse Resolution",
    "trans": [
      {
        "cn": "逆归结"
      }
    ]
  },
  {
    "word": "Isometric Mapping",
    "trans": [
      {
        "cn": "等度量映射"
      }
    ]
  },
  {
    "word": "Jacobian Matrix",
    "trans": [
      {
        "cn": "雅可比矩阵"
      }
    ]
  },
  {
    "word": "Jensen Inequality",
    "trans": [
      {
        "cn": "Jensen不等式"
      }
    ]
  },
  {
    "word": "Joint Probability Distribution",
    "trans": [
      {
        "cn": "联合概率分布"
      }
    ]
  },
  {
    "word": "K-Armed Bandit Problem",
    "trans": [
      {
        "cn": "k-摇臂老虎机"
      }
    ]
  },
  {
    "word": "K-Fold Cross Validation",
    "trans": [
      {
        "cn": "k 折交叉验证"
      }
    ]
  },
  {
    "word": "Karush-Kuhn-Tucker Condition",
    "trans": [
      {
        "cn": "KKT条件"
      }
    ]
  },
  {
    "word": "Karush–Kuhn–Tucker",
    "trans": [
      {
        "cn": "Karush–Kuhn–Tucker"
      }
    ]
  },
  {
    "word": "Kernel Function",
    "trans": [
      {
        "cn": "核函数"
      }
    ]
  },
  {
    "word": "Kernel Method",
    "trans": [
      {
        "cn": "核方法"
      }
    ]
  },
  {
    "word": "Kernel Trick",
    "trans": [
      {
        "cn": "核技巧"
      }
    ]
  },
  {
    "word": "Kernelized Linear Discriminant Analysis",
    "trans": [
      {
        "cn": "核线性判别分析"
      }
    ]
  },
  {
    "word": "KL Divergence",
    "trans": [
      {
        "cn": "KL散度"
      }
    ]
  },
  {
    "word": "L-BFGS",
    "trans": [
      {
        "cn": "L-BFGS"
      }
    ]
  },
  {
    "word": "Label",
    "trans": [
      {
        "cn": "标签/标记"
      }
    ]
  },
  {
    "word": "Label Space",
    "trans": [
      {
        "cn": "标记空间"
      }
    ]
  },
  {
    "word": "Lagrange Duality",
    "trans": [
      {
        "cn": "拉格朗日对偶性"
      }
    ]
  },
  {
    "word": "Lagrange Multiplier",
    "trans": [
      {
        "cn": "拉格朗日乘子"
      }
    ]
  },
  {
    "word": "Language Model",
    "trans": [
      {
        "cn": "语言模型"
      }
    ]
  },
  {
    "word": "Laplace Smoothing",
    "trans": [
      {
        "cn": "拉普拉斯平滑"
      }
    ]
  },
  {
    "word": "Laplacian Correction",
    "trans": [
      {
        "cn": "拉普拉斯修正"
      }
    ]
  },
  {
    "word": "Latent Dirichlet Allocation",
    "trans": [
      {
        "cn": "潜在狄利克雷分配"
      }
    ]
  },
  {
    "word": "Latent Semantic Analysis",
    "trans": [
      {
        "cn": "潜在语义分析"
      }
    ]
  },
  {
    "word": "Latent Variable",
    "trans": [
      {
        "cn": "潜变量/隐变量"
      }
    ]
  },
  {
    "word": "Law of Large Numbers",
    "trans": [
      {
        "cn": "大数定律"
      }
    ]
  },
  {
    "word": "Layer Normalization",
    "trans": [
      {
        "cn": "层规范化"
      }
    ]
  },
  {
    "word": "Lazy Learning",
    "trans": [
      {
        "cn": "懒惰学习"
      }
    ]
  },
  {
    "word": "Leaky Relu",
    "trans": [
      {
        "cn": "泄漏修正线性单元/泄漏整流线性单元"
      }
    ]
  },
  {
    "word": "Learner",
    "trans": [
      {
        "cn": "学习器"
      }
    ]
  },
  {
    "word": "Learning",
    "trans": [
      {
        "cn": "学习"
      }
    ]
  },
  {
    "word": "Learning By Analogy",
    "trans": [
      {
        "cn": "类比学习"
      }
    ]
  },
  {
    "word": "Learning Rate",
    "trans": [
      {
        "cn": "学习率"
      }
    ]
  },
  {
    "word": "Learning Vector Quantization",
    "trans": [
      {
        "cn": "学习向量量化"
      }
    ]
  },
  {
    "word": "Least Square Method",
    "trans": [
      {
        "cn": "最小二乘法"
      }
    ]
  },
  {
    "word": "Least Squares Regression Tree",
    "trans": [
      {
        "cn": "最小二乘回归树"
      }
    ]
  },
  {
    "word": "Left Singular Vector",
    "trans": [
      {
        "cn": "左奇异向量"
      }
    ]
  },
  {
    "word": "Likelihood",
    "trans": [
      {
        "cn": "似然"
      }
    ]
  },
  {
    "word": "Linear Chain Conditional Random Field",
    "trans": [
      {
        "cn": "线性链条件随机场"
      }
    ]
  },
  {
    "word": "Linear Classification Model",
    "trans": [
      {
        "cn": "线性分类模型"
      }
    ]
  },
  {
    "word": "Linear Classifier",
    "trans": [
      {
        "cn": "线性分类器"
      }
    ]
  },
  {
    "word": "Linear Dependence",
    "trans": [
      {
        "cn": "线性相关"
      }
    ]
  },
  {
    "word": "Linear Discriminant Analysis",
    "trans": [
      {
        "cn": "线性判别分析"
      }
    ]
  },
  {
    "word": "Linear Model",
    "trans": [
      {
        "cn": "线性模型"
      }
    ]
  },
  {
    "word": "Linear Regression",
    "trans": [
      {
        "cn": "线性回归"
      }
    ]
  },
  {
    "word": "Link Function",
    "trans": [
      {
        "cn": "联系函数"
      }
    ]
  },
  {
    "word": "Local Markov Property",
    "trans": [
      {
        "cn": "局部马尔可夫性"
      }
    ]
  },
  {
    "word": "Local Minima",
    "trans": [
      {
        "cn": "局部极小"
      }
    ]
  },
  {
    "word": "Local Minimum",
    "trans": [
      {
        "cn": "局部极小"
      }
    ]
  },
  {
    "word": "Local Representation",
    "trans": [
      {
        "cn": "局部式表示/局部式表征"
      }
    ]
  },
  {
    "word": "Log Likelihood",
    "trans": [
      {
        "cn": "对数似然函数"
      }
    ]
  },
  {
    "word": "Log Linear Model",
    "trans": [
      {
        "cn": "对数线性模型"
      }
    ]
  },
  {
    "word": "Log-Likelihood",
    "trans": [
      {
        "cn": "对数似然"
      }
    ]
  },
  {
    "word": "Log-Linear Regression",
    "trans": [
      {
        "cn": "对数线性回归"
      }
    ]
  },
  {
    "word": "Logistic Function",
    "trans": [
      {
        "cn": "对数几率函数"
      }
    ]
  },
  {
    "word": "Logistic Regression",
    "trans": [
      {
        "cn": "对数几率回归"
      }
    ]
  },
  {
    "word": "Logit",
    "trans": [
      {
        "cn": "对数几率"
      }
    ]
  },
  {
    "word": "Long Short Term Memory",
    "trans": [
      {
        "cn": "长短期记忆"
      }
    ]
  },
  {
    "word": "Long Short-Term Memory Network",
    "trans": [
      {
        "cn": "长短期记忆网络"
      }
    ]
  },
  {
    "word": "Loopy Belief Propagation",
    "trans": [
      {
        "cn": "环状信念传播"
      }
    ]
  },
  {
    "word": "Loss Function",
    "trans": [
      {
        "cn": "损失函数"
      }
    ]
  },
  {
    "word": "Low Rank Matrix Approximation",
    "trans": [
      {
        "cn": "低秩矩阵近似"
      }
    ]
  },
  {
    "word": "Machine Learning",
    "trans": [
      {
        "cn": "机器学习"
      }
    ]
  },
  {
    "word": "Macron-R",
    "trans": [
      {
        "cn": "宏查全率"
      }
    ]
  },
  {
    "word": "Manhattan Distance",
    "trans": [
      {
        "cn": "曼哈顿距离"
      }
    ]
  },
  {
    "word": "Manifold",
    "trans": [
      {
        "cn": "流形"
      }
    ]
  },
  {
    "word": "Manifold Assumption",
    "trans": [
      {
        "cn": "流形假设"
      }
    ]
  },
  {
    "word": "Manifold Learning",
    "trans": [
      {
        "cn": "流形学习"
      }
    ]
  },
  {
    "word": "Margin",
    "trans": [
      {
        "cn": "间隔"
      }
    ]
  },
  {
    "word": "Marginal Distribution",
    "trans": [
      {
        "cn": "边缘分布"
      }
    ]
  },
  {
    "word": "Marginal Independence",
    "trans": [
      {
        "cn": "边缘独立性"
      }
    ]
  },
  {
    "word": "Marginalization",
    "trans": [
      {
        "cn": "边缘化"
      }
    ]
  },
  {
    "word": "Markov Chain",
    "trans": [
      {
        "cn": "马尔可夫链"
      }
    ]
  },
  {
    "word": "Markov Chain Monte Carlo",
    "trans": [
      {
        "cn": "马尔可夫链蒙特卡罗"
      }
    ]
  },
  {
    "word": "Markov Decision Process",
    "trans": [
      {
        "cn": "马尔可夫决策过程"
      }
    ]
  },
  {
    "word": "Markov Network",
    "trans": [
      {
        "cn": "马尔可夫网络"
      }
    ]
  },
  {
    "word": "Markov Process",
    "trans": [
      {
        "cn": "马尔可夫过程"
      }
    ]
  },
  {
    "word": "Markov Random Field",
    "trans": [
      {
        "cn": "马尔可夫随机场"
      }
    ]
  },
  {
    "word": "Mask",
    "trans": [
      {
        "cn": "掩码"
      }
    ]
  },
  {
    "word": "Matrix",
    "trans": [
      {
        "cn": "矩阵"
      }
    ]
  },
  {
    "word": "Matrix Inversion",
    "trans": [
      {
        "cn": "逆矩阵"
      }
    ]
  },
  {
    "word": "Max Pooling",
    "trans": [
      {
        "cn": "最大汇聚"
      }
    ]
  },
  {
    "word": "Maximal Clique",
    "trans": [
      {
        "cn": "最大团"
      }
    ]
  },
  {
    "word": "Maximum Entropy Model",
    "trans": [
      {
        "cn": "最大熵模型"
      }
    ]
  },
  {
    "word": "Maximum Likelihood Estimation",
    "trans": [
      {
        "cn": "极大似然估计"
      }
    ]
  },
  {
    "word": "Maximum Margin",
    "trans": [
      {
        "cn": "最大间隔"
      }
    ]
  },
  {
    "word": "Mean Filed",
    "trans": [
      {
        "cn": "平均场"
      }
    ]
  },
  {
    "word": "Mean Pooling",
    "trans": [
      {
        "cn": "平均汇聚"
      }
    ]
  },
  {
    "word": "Mean Squared Error",
    "trans": [
      {
        "cn": "均方误差"
      }
    ]
  },
  {
    "word": "Mean-Field",
    "trans": [
      {
        "cn": "平均场"
      }
    ]
  },
  {
    "word": "Memory Network",
    "trans": [
      {
        "cn": "记忆网络"
      }
    ]
  },
  {
    "word": "Message Passing",
    "trans": [
      {
        "cn": "消息传递"
      }
    ]
  },
  {
    "word": "Metric Learning",
    "trans": [
      {
        "cn": "度量学习"
      }
    ]
  },
  {
    "word": "Micro-R",
    "trans": [
      {
        "cn": "微查全率"
      }
    ]
  },
  {
    "word": "Minibatch",
    "trans": [
      {
        "cn": "小批量"
      }
    ]
  },
  {
    "word": "Minimal Description Length",
    "trans": [
      {
        "cn": "最小描述长度"
      }
    ]
  },
  {
    "word": "Minimax Game",
    "trans": [
      {
        "cn": "极小极大博弈"
      }
    ]
  },
  {
    "word": "Minkowski Distance",
    "trans": [
      {
        "cn": "闵可夫斯基距离"
      }
    ]
  },
  {
    "word": "Mixture of Experts",
    "trans": [
      {
        "cn": "混合专家模型"
      }
    ]
  },
  {
    "word": "Mixture-of-Gaussian",
    "trans": [
      {
        "cn": "高斯混合"
      }
    ]
  },
  {
    "word": "Model",
    "trans": [
      {
        "cn": "模型"
      }
    ]
  },
  {
    "word": "Model Selection",
    "trans": [
      {
        "cn": "模型选择"
      }
    ]
  },
  {
    "word": "Momentum Method",
    "trans": [
      {
        "cn": "动量法"
      }
    ]
  },
  {
    "word": "Monte Carlo Method",
    "trans": [
      {
        "cn": "蒙特卡罗方法"
      }
    ]
  },
  {
    "word": "Moral Graph",
    "trans": [
      {
        "cn": "端正图/道德图"
      }
    ]
  },
  {
    "word": "Moralization",
    "trans": [
      {
        "cn": "道德化"
      }
    ]
  },
  {
    "word": "Multi-Class Classification",
    "trans": [
      {
        "cn": "多分类"
      }
    ]
  },
  {
    "word": "Multi-Head Attention",
    "trans": [
      {
        "cn": "多头注意力"
      }
    ]
  },
  {
    "word": "Multi-Head Self-Attention",
    "trans": [
      {
        "cn": "多头自注意力"
      }
    ]
  },
  {
    "word": "Multi-Kernel Learning",
    "trans": [
      {
        "cn": "多核学习"
      }
    ]
  },
  {
    "word": "Multi-Label Learning",
    "trans": [
      {
        "cn": "多标记学习"
      }
    ]
  },
  {
    "word": "Multi-Layer Feedforward Neural Networks",
    "trans": [
      {
        "cn": "多层前馈神经网络"
      }
    ]
  },
  {
    "word": "Multi-Layer Perceptron",
    "trans": [
      {
        "cn": "多层感知机"
      }
    ]
  },
  {
    "word": "Multinomial Distribution",
    "trans": [
      {
        "cn": "多项分布"
      }
    ]
  },
  {
    "word": "Multiple Dimensional Scaling",
    "trans": [
      {
        "cn": "多维缩放"
      }
    ]
  },
  {
    "word": "Multiple Linear Regression",
    "trans": [
      {
        "cn": "多元线性回归"
      }
    ]
  },
  {
    "word": "Multitask Learning",
    "trans": [
      {
        "cn": "多任务学习"
      }
    ]
  },
  {
    "word": "Multivariate Normal Distribution",
    "trans": [
      {
        "cn": "多元正态分布"
      }
    ]
  },
  {
    "word": "Mutual Information",
    "trans": [
      {
        "cn": "互信息"
      }
    ]
  },
  {
    "word": "N-Gram Model",
    "trans": [
      {
        "cn": "N元模型"
      }
    ]
  },
  {
    "word": "Naive Bayes Classifier",
    "trans": [
      {
        "cn": "朴素贝叶斯分类器"
      }
    ]
  },
  {
    "word": "Naive Bayes",
    "trans": [
      {
        "cn": "朴素贝叶斯"
      }
    ]
  },
  {
    "word": "Nearest Neighbor Classifier",
    "trans": [
      {
        "cn": "最近邻分类器"
      }
    ]
  },
  {
    "word": "Negative Log Likelihood",
    "trans": [
      {
        "cn": "负对数似然函数"
      }
    ]
  },
  {
    "word": "Neighbourhood Component Analysis",
    "trans": [
      {
        "cn": "近邻成分分析"
      }
    ]
  },
  {
    "word": "Net Input",
    "trans": [
      {
        "cn": "净输入"
      }
    ]
  },
  {
    "word": "Neural Network",
    "trans": [
      {
        "cn": "神经网络"
      }
    ]
  },
  {
    "word": "Neural Turing Machine",
    "trans": [
      {
        "cn": "神经图灵机"
      }
    ]
  },
  {
    "word": "Neuron",
    "trans": [
      {
        "cn": "神经元"
      }
    ]
  },
  {
    "word": "Newton Method",
    "trans": [
      {
        "cn": "牛顿法"
      }
    ]
  },
  {
    "word": "No Free Lunch Theorem",
    "trans": [
      {
        "cn": "没有免费午餐定理"
      }
    ]
  },
  {
    "word": "Noise-Contrastive Estimation",
    "trans": [
      {
        "cn": "噪声对比估计"
      }
    ]
  },
  {
    "word": "Nominal Attribute",
    "trans": [
      {
        "cn": "列名属性"
      }
    ]
  },
  {
    "word": "Non-Convex Optimization",
    "trans": [
      {
        "cn": "非凸优化"
      }
    ]
  },
  {
    "word": "Non-Metric Distance",
    "trans": [
      {
        "cn": "非度量距离"
      }
    ]
  },
  {
    "word": "Non-Negative Matrix Factorization",
    "trans": [
      {
        "cn": "非负矩阵分解"
      }
    ]
  },
  {
    "word": "Non-Ordinal Attribute",
    "trans": [
      {
        "cn": "无序属性"
      }
    ]
  },
  {
    "word": "Norm",
    "trans": [
      {
        "cn": "范数"
      }
    ]
  },
  {
    "word": "Normal Distribution",
    "trans": [
      {
        "cn": "正态分布"
      }
    ]
  },
  {
    "word": "Normalization",
    "trans": [
      {
        "cn": "规范化"
      }
    ]
  },
  {
    "word": "Nuclear Norm",
    "trans": [
      {
        "cn": "核范数"
      }
    ]
  },
  {
    "word": "Number of Epochs",
    "trans": [
      {
        "cn": "轮数"
      }
    ]
  },
  {
    "word": "Numerical Attribute",
    "trans": [
      {
        "cn": "数值属性"
      }
    ]
  },
  {
    "word": "Object Detection",
    "trans": [
      {
        "cn": "目标检测"
      }
    ]
  },
  {
    "word": "Oblique Decision Tree",
    "trans": [
      {
        "cn": "斜决策树"
      }
    ]
  },
  {
    "word": "Occam's Razor",
    "trans": [
      {
        "cn": "奥卡姆剃刀"
      }
    ]
  },
  {
    "word": "Odds",
    "trans": [
      {
        "cn": "几率"
      }
    ]
  },
  {
    "word": "Off-Policy",
    "trans": [
      {
        "cn": "异策略"
      }
    ]
  },
  {
    "word": "On-Policy",
    "trans": [
      {
        "cn": "同策略"
      }
    ]
  },
  {
    "word": "One-Shot Learning",
    "trans": [
      {
        "cn": "单试学习"
      }
    ]
  },
  {
    "word": "One-Dependent Estimator",
    "trans": [
      {
        "cn": "独依赖估计"
      }
    ]
  },
  {
    "word": "One-Hot",
    "trans": [
      {
        "cn": "独热"
      }
    ]
  },
  {
    "word": "Online Learning",
    "trans": [
      {
        "cn": "在线学习"
      }
    ]
  },
  {
    "word": "Optimizer",
    "trans": [
      {
        "cn": "优化器"
      }
    ]
  },
  {
    "word": "Ordinal Attribute",
    "trans": [
      {
        "cn": "有序属性"
      }
    ]
  },
  {
    "word": "Orthogonal",
    "trans": [
      {
        "cn": "正交"
      }
    ]
  },
  {
    "word": "Orthogonal Matrix",
    "trans": [
      {
        "cn": "正交矩阵"
      }
    ]
  },
  {
    "word": "Out-Of-Bag Estimate",
    "trans": [
      {
        "cn": "包外估计"
      }
    ]
  },
  {
    "word": "Outlier",
    "trans": [
      {
        "cn": "异常点"
      }
    ]
  },
  {
    "word": "Over-Parameterized",
    "trans": [
      {
        "cn": "过度参数化"
      }
    ]
  },
  {
    "word": "Overfitting",
    "trans": [
      {
        "cn": "过拟合"
      }
    ]
  },
  {
    "word": "Oversampling",
    "trans": [
      {
        "cn": "过采样"
      }
    ]
  },
  {
    "word": "Pac-Learnable",
    "trans": [
      {
        "cn": "PAC可学习"
      }
    ]
  },
  {
    "word": "Padding",
    "trans": [
      {
        "cn": "填充"
      }
    ]
  },
  {
    "word": "Pairwise Markov Property",
    "trans": [
      {
        "cn": "成对马尔可夫性"
      }
    ]
  },
  {
    "word": "Parallel Distributed Processing",
    "trans": [
      {
        "cn": "分布式并行处理"
      }
    ]
  },
  {
    "word": "Parameter",
    "trans": [
      {
        "cn": "参数"
      }
    ]
  },
  {
    "word": "Parameter Estimation",
    "trans": [
      {
        "cn": "参数估计"
      }
    ]
  },
  {
    "word": "Parameter Space",
    "trans": [
      {
        "cn": "参数空间"
      }
    ]
  },
  {
    "word": "Parameter Tuning",
    "trans": [
      {
        "cn": "调参"
      }
    ]
  },
  {
    "word": "Parametric ReLU",
    "trans": [
      {
        "cn": "参数化修正线性单元/参数化整流线性单元"
      }
    ]
  },
  {
    "word": "Part-Of-Speech Tagging",
    "trans": [
      {
        "cn": "词性标注"
      }
    ]
  },
  {
    "word": "Partial Derivative",
    "trans": [
      {
        "cn": "偏导数"
      }
    ]
  },
  {
    "word": "Partially Observable Markov Decision Processes",
    "trans": [
      {
        "cn": "部分可观测马尔可夫决策过程"
      }
    ]
  },
  {
    "word": "Partition Function",
    "trans": [
      {
        "cn": "配分函数"
      }
    ]
  },
  {
    "word": "Perceptron",
    "trans": [
      {
        "cn": "感知机"
      }
    ]
  },
  {
    "word": "Performance Measure",
    "trans": [
      {
        "cn": "性能度量"
      }
    ]
  },
  {
    "word": "Perplexity",
    "trans": [
      {
        "cn": "困惑度"
      }
    ]
  },
  {
    "word": "Pointer Network",
    "trans": [
      {
        "cn": "指针网络"
      }
    ]
  },
  {
    "word": "Policy",
    "trans": [
      {
        "cn": "策略"
      }
    ]
  },
  {
    "word": "Policy Gradient",
    "trans": [
      {
        "cn": "策略梯度"
      }
    ]
  },
  {
    "word": "Policy Iteration",
    "trans": [
      {
        "cn": "策略迭代"
      }
    ]
  },
  {
    "word": "Polynomial Kernel Function",
    "trans": [
      {
        "cn": "多项式核函数"
      }
    ]
  },
  {
    "word": "Pooling",
    "trans": [
      {
        "cn": "汇聚"
      }
    ]
  },
  {
    "word": "Pooling Layer",
    "trans": [
      {
        "cn": "汇聚层"
      }
    ]
  },
  {
    "word": "Positive Definite Matrix",
    "trans": [
      {
        "cn": "正定矩阵"
      }
    ]
  },
  {
    "word": "Post-Pruning",
    "trans": [
      {
        "cn": "后剪枝"
      }
    ]
  },
  {
    "word": "Potential Function",
    "trans": [
      {
        "cn": "势函数"
      }
    ]
  },
  {
    "word": "Power Method",
    "trans": [
      {
        "cn": "幂法"
      }
    ]
  },
  {
    "word": "Pre-Training",
    "trans": [
      {
        "cn": "预训练"
      }
    ]
  },
  {
    "word": "Precision",
    "trans": [
      {
        "cn": "查准率/准确率"
      }
    ]
  },
  {
    "word": "Prepruning",
    "trans": [
      {
        "cn": "预剪枝"
      }
    ]
  },
  {
    "word": "Primal Problem",
    "trans": [
      {
        "cn": "主问题"
      }
    ]
  },
  {
    "word": "Primary Visual Cortex",
    "trans": [
      {
        "cn": "初级视觉皮层"
      }
    ]
  },
  {
    "word": "Principal Component Analysis",
    "trans": [
      {
        "cn": "主成分分析"
      }
    ]
  },
  {
    "word": "Prior",
    "trans": [
      {
        "cn": "先验"
      }
    ]
  },
  {
    "word": "Probabilistic Context-Free Grammar",
    "trans": [
      {
        "cn": "概率上下文无关文法"
      }
    ]
  },
  {
    "word": "Probabilistic Graphical Model",
    "trans": [
      {
        "cn": "概率图模型"
      }
    ]
  },
  {
    "word": "Probabilistic Model",
    "trans": [
      {
        "cn": "概率模型"
      }
    ]
  },
  {
    "word": "Probability Density Function",
    "trans": [
      {
        "cn": "概率密度函数"
      }
    ]
  },
  {
    "word": "Probability Distribution",
    "trans": [
      {
        "cn": "概率分布"
      }
    ]
  },
  {
    "word": "Probably Approximately Correct",
    "trans": [
      {
        "cn": "概率近似正确"
      }
    ]
  },
  {
    "word": "Proposal Distribution",
    "trans": [
      {
        "cn": "提议分布"
      }
    ]
  },
  {
    "word": "Prototype-Based Clustering",
    "trans": [
      {
        "cn": "原型聚类"
      }
    ]
  },
  {
    "word": "Proximal Gradient Descent",
    "trans": [
      {
        "cn": "近端梯度下降"
      }
    ]
  },
  {
    "word": "Pruning",
    "trans": [
      {
        "cn": "剪枝"
      }
    ]
  },
  {
    "word": "Quadratic Loss Function",
    "trans": [
      {
        "cn": "平方损失函数"
      }
    ]
  },
  {
    "word": "Quadratic Programming",
    "trans": [
      {
        "cn": "二次规划"
      }
    ]
  },
  {
    "word": "Quasi Newton Method",
    "trans": [
      {
        "cn": "拟牛顿法"
      }
    ]
  },
  {
    "word": "Radial Basis Function",
    "trans": [
      {
        "cn": "径向基函数"
      }
    ]
  },
  {
    "word": "Random Forest",
    "trans": [
      {
        "cn": "随机森林"
      }
    ]
  },
  {
    "word": "Random Sampling",
    "trans": [
      {
        "cn": "随机采样"
      }
    ]
  },
  {
    "word": "Random Search",
    "trans": [
      {
        "cn": "随机搜索"
      }
    ]
  },
  {
    "word": "Random Variable",
    "trans": [
      {
        "cn": "随机变量"
      }
    ]
  },
  {
    "word": "Random Walk",
    "trans": [
      {
        "cn": "随机游走"
      }
    ]
  },
  {
    "word": "Recall",
    "trans": [
      {
        "cn": "查全率/召回率"
      }
    ]
  },
  {
    "word": "Receptive Field",
    "trans": [
      {
        "cn": "感受野"
      }
    ]
  },
  {
    "word": "Reconstruction Error",
    "trans": [
      {
        "cn": "重构误差"
      }
    ]
  },
  {
    "word": "Rectified Linear Unit",
    "trans": [
      {
        "cn": "修正线性单元/整流线性单元"
      }
    ]
  },
  {
    "word": "Recurrent Neural Network",
    "trans": [
      {
        "cn": "循环神经网络"
      }
    ]
  },
  {
    "word": "Recursive Neural Network",
    "trans": [
      {
        "cn": "递归神经网络"
      }
    ]
  },
  {
    "word": "Regression",
    "trans": [
      {
        "cn": "回归"
      }
    ]
  },
  {
    "word": "Regularization",
    "trans": [
      {
        "cn": "正则化"
      }
    ]
  },
  {
    "word": "Regularizer",
    "trans": [
      {
        "cn": "正则化项"
      }
    ]
  },
  {
    "word": "Reinforcement Learning",
    "trans": [
      {
        "cn": "强化学习"
      }
    ]
  },
  {
    "word": "Relative Entropy",
    "trans": [
      {
        "cn": "相对熵"
      }
    ]
  },
  {
    "word": "Reparameterization",
    "trans": [
      {
        "cn": "再参数化/重参数化"
      }
    ]
  },
  {
    "word": "Representation",
    "trans": [
      {
        "cn": "表示"
      }
    ]
  },
  {
    "word": "Representation Learning",
    "trans": [
      {
        "cn": "表示学习"
      }
    ]
  },
  {
    "word": "Representer Theorem",
    "trans": [
      {
        "cn": "表示定理"
      }
    ]
  },
  {
    "word": "Reproducing Kernel Hilbert Space",
    "trans": [
      {
        "cn": "再生核希尔伯特空间"
      }
    ]
  },
  {
    "word": "Rescaling",
    "trans": [
      {
        "cn": "再缩放"
      }
    ]
  },
  {
    "word": "Reset Gate",
    "trans": [
      {
        "cn": "重置门"
      }
    ]
  },
  {
    "word": "Residual Connection",
    "trans": [
      {
        "cn": "残差连接"
      }
    ]
  },
  {
    "word": "Residual Network",
    "trans": [
      {
        "cn": "残差网络"
      }
    ]
  },
  {
    "word": "Restricted Boltzmann Machine",
    "trans": [
      {
        "cn": "受限玻尔兹曼机"
      }
    ]
  },
  {
    "word": "Reward",
    "trans": [
      {
        "cn": "奖励"
      }
    ]
  },
  {
    "word": "Ridge Regression",
    "trans": [
      {
        "cn": "岭回归"
      }
    ]
  },
  {
    "word": "Right Singular Vector",
    "trans": [
      {
        "cn": "右奇异向量"
      }
    ]
  },
  {
    "word": "Risk",
    "trans": [
      {
        "cn": "风险"
      }
    ]
  },
  {
    "word": "Robustness",
    "trans": [
      {
        "cn": "稳健性"
      }
    ]
  },
  {
    "word": "Root Node",
    "trans": [
      {
        "cn": "根结点"
      }
    ]
  },
  {
    "word": "Rule Learning",
    "trans": [
      {
        "cn": "规则学习"
      }
    ]
  },
  {
    "word": "Saddle Point",
    "trans": [
      {
        "cn": "鞍点"
      }
    ]
  },
  {
    "word": "Sample",
    "trans": [
      {
        "cn": "样本"
      }
    ]
  },
  {
    "word": "Sample Complexity",
    "trans": [
      {
        "cn": "样本复杂度"
      }
    ]
  },
  {
    "word": "Sample Space",
    "trans": [
      {
        "cn": "样本空间"
      }
    ]
  },
  {
    "word": "Scalar",
    "trans": [
      {
        "cn": "标量"
      }
    ]
  },
  {
    "word": "Selective Ensemble",
    "trans": [
      {
        "cn": "选择性集成"
      }
    ]
  },
  {
    "word": "Self Information",
    "trans": [
      {
        "cn": "自信息"
      }
    ]
  },
  {
    "word": "Self-Attention",
    "trans": [
      {
        "cn": "自注意力"
      }
    ]
  },
  {
    "word": "Self-Organizing Map",
    "trans": [
      {
        "cn": "自组织映射网"
      }
    ]
  },
  {
    "word": "Self-Training",
    "trans": [
      {
        "cn": "自训练"
      }
    ]
  },
  {
    "word": "Semi-Definite Programming",
    "trans": [
      {
        "cn": "半正定规划"
      }
    ]
  },
  {
    "word": "Semi-Naive Bayes Classifiers",
    "trans": [
      {
        "cn": "半朴素贝叶斯分类器"
      }
    ]
  },
  {
    "word": "Semi-Restricted Boltzmann Machine",
    "trans": [
      {
        "cn": "半受限玻尔兹曼机"
      }
    ]
  },
  {
    "word": "Semi-Supervised Clustering",
    "trans": [
      {
        "cn": "半监督聚类"
      }
    ]
  },
  {
    "word": "Semi-Supervised Learning",
    "trans": [
      {
        "cn": "半监督学习"
      }
    ]
  },
  {
    "word": "Semi-Supervised Support Vector Machine",
    "trans": [
      {
        "cn": "半监督支持向量机"
      }
    ]
  },
  {
    "word": "Sentiment Analysis",
    "trans": [
      {
        "cn": "情感分析"
      }
    ]
  },
  {
    "word": "Separating Hyperplane",
    "trans": [
      {
        "cn": "分离超平面"
      }
    ]
  },
  {
    "word": "Sequential Covering",
    "trans": [
      {
        "cn": "序贯覆盖"
      }
    ]
  },
  {
    "word": "Sigmoid Belief Network",
    "trans": [
      {
        "cn": "Sigmoid信念网络"
      }
    ]
  },
  {
    "word": "Sigmoid Function",
    "trans": [
      {
        "cn": "Sigmoid函数"
      }
    ]
  },
  {
    "word": "Signed Distance",
    "trans": [
      {
        "cn": "带符号距离"
      }
    ]
  },
  {
    "word": "Similarity Measure",
    "trans": [
      {
        "cn": "相似度度量"
      }
    ]
  },
  {
    "word": "Simulated Annealing",
    "trans": [
      {
        "cn": "模拟退火"
      }
    ]
  },
  {
    "word": "Simultaneous Localization And Mapping",
    "trans": [
      {
        "cn": "即时定位与地图构建"
      }
    ]
  },
  {
    "word": "Singular Value",
    "trans": [
      {
        "cn": "奇异值"
      }
    ]
  },
  {
    "word": "Singular Value Decomposition",
    "trans": [
      {
        "cn": "奇异值分解"
      }
    ]
  },
  {
    "word": "Skip-Gram Model",
    "trans": [
      {
        "cn": "跳元模型"
      }
    ]
  },
  {
    "word": "Smoothing",
    "trans": [
      {
        "cn": "平滑"
      }
    ]
  },
  {
    "word": "Soft Margin",
    "trans": [
      {
        "cn": "软间隔"
      }
    ]
  },
  {
    "word": "Soft Margin Maximization",
    "trans": [
      {
        "cn": "软间隔最大化"
      }
    ]
  },
  {
    "word": "Softmax",
    "trans": [
      {
        "cn": "Softmax/软最大化"
      }
    ]
  },
  {
    "word": "Softmax Function",
    "trans": [
      {
        "cn": "Softmax函数/软最大化函数"
      }
    ]
  },
  {
    "word": "Softmax Regression",
    "trans": [
      {
        "cn": "Softmax回归/软最大化回归"
      }
    ]
  },
  {
    "word": "Softplus Function",
    "trans": [
      {
        "cn": "Softplus函数"
      }
    ]
  },
  {
    "word": "Span",
    "trans": [
      {
        "cn": "张成子空间"
      }
    ]
  },
  {
    "word": "Sparse Coding",
    "trans": [
      {
        "cn": "稀疏编码"
      }
    ]
  },
  {
    "word": "Sparse Representation",
    "trans": [
      {
        "cn": "稀疏表示"
      }
    ]
  },
  {
    "word": "Sparsity",
    "trans": [
      {
        "cn": "稀疏性"
      }
    ]
  },
  {
    "word": "Specialization",
    "trans": [
      {
        "cn": "特化"
      }
    ]
  },
  {
    "word": "Splitting Variable",
    "trans": [
      {
        "cn": "切分变量"
      }
    ]
  },
  {
    "word": "Squashing Function",
    "trans": [
      {
        "cn": "挤压函数"
      }
    ]
  },
  {
    "word": "Standard Normal Distribution",
    "trans": [
      {
        "cn": "标准正态分布"
      }
    ]
  },
  {
    "word": "State",
    "trans": [
      {
        "cn": "状态"
      }
    ]
  },
  {
    "word": "State Value Function",
    "trans": [
      {
        "cn": "状态值函数"
      }
    ]
  },
  {
    "word": "State-Action Value Function",
    "trans": [
      {
        "cn": "状态-动作值函数"
      }
    ]
  },
  {
    "word": "Stationary Distribution",
    "trans": [
      {
        "cn": "平稳分布"
      }
    ]
  },
  {
    "word": "Stationary Point",
    "trans": [
      {
        "cn": "驻点"
      }
    ]
  },
  {
    "word": "Statistical Learning",
    "trans": [
      {
        "cn": "统计学习"
      }
    ]
  },
  {
    "word": "Steepest Descent",
    "trans": [
      {
        "cn": "最速下降法"
      }
    ]
  },
  {
    "word": "Stochastic Gradient Descent",
    "trans": [
      {
        "cn": "随机梯度下降"
      }
    ]
  },
  {
    "word": "Stochastic Matrix",
    "trans": [
      {
        "cn": "随机矩阵"
      }
    ]
  },
  {
    "word": "Stochastic Process",
    "trans": [
      {
        "cn": "随机过程"
      }
    ]
  },
  {
    "word": "Stratified Sampling",
    "trans": [
      {
        "cn": "分层采样"
      }
    ]
  },
  {
    "word": "Stride",
    "trans": [
      {
        "cn": "步幅"
      }
    ]
  },
  {
    "word": "Structural Risk",
    "trans": [
      {
        "cn": "结构风险"
      }
    ]
  },
  {
    "word": "Structural Risk Minimization",
    "trans": [
      {
        "cn": "结构风险最小化"
      }
    ]
  },
  {
    "word": "Subsample",
    "trans": [
      {
        "cn": "子采样"
      }
    ]
  },
  {
    "word": "Subsampling",
    "trans": [
      {
        "cn": "下采样"
      }
    ]
  },
  {
    "word": "Subset Search",
    "trans": [
      {
        "cn": "子集搜索"
      }
    ]
  },
  {
    "word": "Subspace",
    "trans": [
      {
        "cn": "子空间"
      }
    ]
  },
  {
    "word": "Supervised Learning",
    "trans": [
      {
        "cn": "监督学习"
      }
    ]
  },
  {
    "word": "Support Vector",
    "trans": [
      {
        "cn": "支持向量"
      }
    ]
  },
  {
    "word": "Support Vector Expansion",
    "trans": [
      {
        "cn": "支持向量展式"
      }
    ]
  },
  {
    "word": "Support Vector Machine",
    "trans": [
      {
        "cn": "支持向量机"
      }
    ]
  },
  {
    "word": "Surrogat Loss",
    "trans": [
      {
        "cn": "替代损失"
      }
    ]
  },
  {
    "word": "Surrogate Function",
    "trans": [
      {
        "cn": "替代函数"
      }
    ]
  },
  {
    "word": "Surrogate Loss Function",
    "trans": [
      {
        "cn": "代理损失函数"
      }
    ]
  },
  {
    "word": "Symbolism",
    "trans": [
      {
        "cn": "符号主义"
      }
    ]
  },
  {
    "word": "Tangent Propagation",
    "trans": [
      {
        "cn": "正切传播"
      }
    ]
  },
  {
    "word": "Teacher Forcing",
    "trans": [
      {
        "cn": "强制教学"
      }
    ]
  },
  {
    "word": "Temporal-Difference Learning",
    "trans": [
      {
        "cn": "时序差分学习"
      }
    ]
  },
  {
    "word": "Tensor",
    "trans": [
      {
        "cn": "张量"
      }
    ]
  },
  {
    "word": "Test Error",
    "trans": [
      {
        "cn": "测试误差"
      }
    ]
  },
  {
    "word": "Test Sample",
    "trans": [
      {
        "cn": "测试样本"
      }
    ]
  },
  {
    "word": "Test Set",
    "trans": [
      {
        "cn": "测试集"
      }
    ]
  },
  {
    "word": "Threshold",
    "trans": [
      {
        "cn": "阈值"
      }
    ]
  },
  {
    "word": "Threshold Logic Unit",
    "trans": [
      {
        "cn": "阈值逻辑单元"
      }
    ]
  },
  {
    "word": "Threshold-Moving",
    "trans": [
      {
        "cn": "阈值移动"
      }
    ]
  },
  {
    "word": "Tied Weight",
    "trans": [
      {
        "cn": "捆绑权重"
      }
    ]
  },
  {
    "word": "Tikhonov Regularization",
    "trans": [
      {
        "cn": "Tikhonov正则化"
      }
    ]
  },
  {
    "word": "Time Delay Neural Network",
    "trans": [
      {
        "cn": "时延神经网络"
      }
    ]
  },
  {
    "word": "Time Homogenous Markov Chain",
    "trans": [
      {
        "cn": "时间齐次马尔可夫链"
      }
    ]
  },
  {
    "word": "Time Step",
    "trans": [
      {
        "cn": "时间步"
      }
    ]
  },
  {
    "word": "Token",
    "trans": [
      {
        "cn": "词元"
      }
    ]
  },
  {
    "word": "Tokenize",
    "trans": [
      {
        "cn": "词元化"
      }
    ]
  },
  {
    "word": "Tokenization",
    "trans": [
      {
        "cn": "词元化"
      }
    ]
  },
  {
    "word": "Tokenizer",
    "trans": [
      {
        "cn": "词元分析器"
      }
    ]
  },
  {
    "word": "Topic Model",
    "trans": [
      {
        "cn": "话题模型"
      }
    ]
  },
  {
    "word": "Topic Modeling",
    "trans": [
      {
        "cn": "话题分析"
      }
    ]
  },
  {
    "word": "Trace",
    "trans": [
      {
        "cn": "迹"
      }
    ]
  },
  {
    "word": "Training",
    "trans": [
      {
        "cn": "训练"
      }
    ]
  },
  {
    "word": "Training Error",
    "trans": [
      {
        "cn": "训练误差"
      }
    ]
  },
  {
    "word": "Training Sample",
    "trans": [
      {
        "cn": "训练样本"
      }
    ]
  },
  {
    "word": "Training Set",
    "trans": [
      {
        "cn": "训练集"
      }
    ]
  },
  {
    "word": "Transductive Learning",
    "trans": [
      {
        "cn": "直推学习"
      }
    ]
  },
  {
    "word": "Transductive Transfer Learning",
    "trans": [
      {
        "cn": "直推迁移学习"
      }
    ]
  },
  {
    "word": "Transfer Learning",
    "trans": [
      {
        "cn": "迁移学习"
      }
    ]
  },
  {
    "word": "Transformer",
    "trans": [
      {
        "cn": "Transformer"
      }
    ]
  },
  {
    "word": "Transformer Model",
    "trans": [
      {
        "cn": "Transformer模型"
      }
    ]
  },
  {
    "word": "Transpose",
    "trans": [
      {
        "cn": "转置"
      }
    ]
  },
  {
    "word": "Transposed Convolution",
    "trans": [
      {
        "cn": "转置卷积"
      }
    ]
  },
  {
    "word": "Trial And Error",
    "trans": [
      {
        "cn": "试错"
      }
    ]
  },
  {
    "word": "Trigram",
    "trans": [
      {
        "cn": "三元语法"
      }
    ]
  },
  {
    "word": "Turing Machine",
    "trans": [
      {
        "cn": "图灵机"
      }
    ]
  },
  {
    "word": "Underfitting",
    "trans": [
      {
        "cn": "欠拟合"
      }
    ]
  },
  {
    "word": "Undersampling",
    "trans": [
      {
        "cn": "欠采样"
      }
    ]
  },
  {
    "word": "Undirected Graphical Model",
    "trans": [
      {
        "cn": "无向图模型"
      }
    ]
  },
  {
    "word": "Uniform Distribution",
    "trans": [
      {
        "cn": "均匀分布"
      }
    ]
  },
  {
    "word": "Unigram",
    "trans": [
      {
        "cn": "一元语法"
      }
    ]
  },
  {
    "word": "Unit",
    "trans": [
      {
        "cn": "单元"
      }
    ]
  },
  {
    "word": "Universal Approximation Theorem",
    "trans": [
      {
        "cn": "通用近似定理"
      }
    ]
  },
  {
    "word": "Universal Approximator",
    "trans": [
      {
        "cn": "通用近似器"
      }
    ]
  },
  {
    "word": "Universal Function Approximator",
    "trans": [
      {
        "cn": "通用函数近似器"
      }
    ]
  },
  {
    "word": "Unknown Token",
    "trans": [
      {
        "cn": "未知词元"
      }
    ]
  },
  {
    "word": "Unsupervised Layer-Wise Training",
    "trans": [
      {
        "cn": "无监督逐层训练"
      }
    ]
  },
  {
    "word": "Unsupervised Learning",
    "trans": [
      {
        "cn": "无监督学习"
      }
    ]
  },
  {
    "word": "Update Gate",
    "trans": [
      {
        "cn": "更新门"
      }
    ]
  },
  {
    "word": "Upsampling",
    "trans": [
      {
        "cn": "上采样"
      }
    ]
  },
  {
    "word": "V-Structure",
    "trans": [
      {
        "cn": "V型结构"
      }
    ]
  },
  {
    "word": "Validation Set",
    "trans": [
      {
        "cn": "验证集"
      }
    ]
  },
  {
    "word": "Validity Index",
    "trans": [
      {
        "cn": "有效性指标"
      }
    ]
  },
  {
    "word": "Value Function Approximation",
    "trans": [
      {
        "cn": "值函数近似"
      }
    ]
  },
  {
    "word": "Value Iteration",
    "trans": [
      {
        "cn": "值迭代"
      }
    ]
  },
  {
    "word": "Vanishing Gradient Problem",
    "trans": [
      {
        "cn": "梯度消失问题"
      }
    ]
  },
  {
    "word": "Vapnik-Chervonenkis Dimension",
    "trans": [
      {
        "cn": "VC维"
      }
    ]
  },
  {
    "word": "Variable Elimination",
    "trans": [
      {
        "cn": "变量消去"
      }
    ]
  },
  {
    "word": "Variance",
    "trans": [
      {
        "cn": "方差"
      }
    ]
  },
  {
    "word": "Variational Autoencoder",
    "trans": [
      {
        "cn": "变分自编码器"
      }
    ]
  },
  {
    "word": "Variational Inference",
    "trans": [
      {
        "cn": "变分推断"
      }
    ]
  },
  {
    "word": "Vector",
    "trans": [
      {
        "cn": "向量"
      }
    ]
  },
  {
    "word": "Vector Space Model",
    "trans": [
      {
        "cn": "向量空间模型"
      }
    ]
  },
  {
    "word": "Version Space",
    "trans": [
      {
        "cn": "版本空间"
      }
    ]
  },
  {
    "word": "Viterbi Algorithm",
    "trans": [
      {
        "cn": "维特比算法"
      }
    ]
  },
  {
    "word": "Vocabulary",
    "trans": [
      {
        "cn": "词表"
      }
    ]
  },
  {
    "word": "Warp",
    "trans": [
      {
        "cn": "线程束"
      }
    ]
  },
  {
    "word": "Weak Learner",
    "trans": [
      {
        "cn": "弱学习器"
      }
    ]
  },
  {
    "word": "Weakly Supervised Learning",
    "trans": [
      {
        "cn": "弱监督学习"
      }
    ]
  },
  {
    "word": "Weight",
    "trans": [
      {
        "cn": "权重"
      }
    ]
  },
  {
    "word": "Weight Decay",
    "trans": [
      {
        "cn": "权重衰减"
      }
    ]
  },
  {
    "word": "Weight Sharing",
    "trans": [
      {
        "cn": "权共享"
      }
    ]
  },
  {
    "word": "Weighted Voting",
    "trans": [
      {
        "cn": "加权投票"
      }
    ]
  },
  {
    "word": "Whitening",
    "trans": [
      {
        "cn": "白化"
      }
    ]
  },
  {
    "word": "Winner-Take-All",
    "trans": [
      {
        "cn": "胜者通吃"
      }
    ]
  },
  {
    "word": "Within-Class Scatter Matrix",
    "trans": [
      {
        "cn": "类内散度矩阵"
      }
    ]
  },
  {
    "word": "Word Embedding",
    "trans": [
      {
        "cn": "词嵌入"
      }
    ]
  },
  {
    "word": "Word Sense Disambiguation",
    "trans": [
      {
        "cn": "词义消歧"
      }
    ]
  },
  {
    "word": "Word Vector",
    "trans": [
      {
        "cn": "词向量"
      }
    ]
  },
  {
    "word": "Zero Padding",
    "trans": [
      {
        "cn": "零填充"
      }
    ]
  },
  {
    "word": "Zero-Shot Learning",
    "trans": [
      {
        "cn": "零试学习"
      }
    ]
  },
  {
    "word": "Zipf's Law",
    "trans": [
      {
        "cn": "齐普夫定律"
      }
    ]
  }
]